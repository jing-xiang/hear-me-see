# hear-me-see
HearMeSee is an AI-driven application specifically designed to improve the quality of life of visually-impaired individuals. Using cutting-edge image detection and voice recognition technology, HearMeSee assists its users by identifying and providing detailed descriptions of objects or obstacles within their environment. The application delivers real-time feedback, enhancing navigation safety. With the help of HearMeSee, user independence, and convenience are promoted.


# About

HearMeSee is built using Android Studio, leveraging its comprehensive toolset and debugging capabilities. With a focus on user-centered design, we conduct extensive user research and feedback incorporation to ensure an intuitive and accessible user interface development process. Regular code reviews and automated testing to preemptively address potential issues show our commitment to providing a high-quality application. Emphasizing user-centered design, we incorporate user feedback and conduct rigorous user research to create an intuitive, accessible interface. 

We employ continuous integration, deployment pipelines, and automated testing for an efficient development cycle. User acceptance testing is used to further fine-tune the application's functionality, ensuring a reliable, user-friendly experience for visually disabled individuals.

# Features

Object Detection: Objects and obstacles near the user are located and identified in real-time. By utilizing the smartphone's camera, visually disabled individuals can easily capture their surroundings about what is in front of them. This feature eliminates the uncertainty and safety hazards associated with unidentified objects, allowing users to navigate their environment more confidently.

Voice Recognition: The advanced voice recognition system seamlessly translates spoken commands into actions, making it effortless for users to interact with the application. Whether it's identifying items or exploring unfamiliar territories, HearMeSee ensures accurate recognition and effortless usability.

Real-Time Feedback: HearMeSee offers real-time audio feedback, describing objects or obstacles captured by the camera. Users receive instant and detailed information about the items in their surroundings, ensuring enhanced safety and independence. Through real-time object recognition, comprehensive audio feedback, and user-friendly accessibility, HearMeSee enhances the independence, safety, and overall quality of life for visually disabled individuals.

Location Tracking: HearMeSee empowers caregivers and family members to monitor the user's location and promptly respond to any potential hazards. By leveraging real-time tracking, hazard detection, instant notifications, and customizable settings, HearMeSee enhances the overall safety and well-being of visually disabled individuals, providing peace of mind for both users and their support network.

# Tech Stack

Android Studio: Primary Integrated Development Environment (IDE) for Android app development.

JavaScript: Used for scripting parts of user interface and server interactions.

TensorFlow: Used for implementing object detection and image recognition capabilities.

Google Cloud (Speech-to-Text): Used for converting voice commands into text for processing.

React Native: Used for developing parts of the application's user interface.
